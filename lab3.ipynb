{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6386fe9e",
   "metadata": {},
   "source": [
    "### Preparación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135a98ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f696cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se encuentran las imágenes\n",
    "IMAGE_PATH = \"data/UTKFACE\"\n",
    "\n",
    "# Regex para capturar las etiquetas de género en el nombre del archivo\n",
    "# [age]_[gender]_[race]_[date&time].jpg.chip.jpg\n",
    "FILENAME_PATTERN = re.compile(r\"\\d+_([01])_[0-4]_\\d+.jpg.chip.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf4a392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtrando imágenes: 100%|██████████| 23708/23708 [00:00<00:00, 214842.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡Filtrado completado con éxito!\n",
      "\n",
      "Imágenes con etiqueta inválida: 4\n",
      "- 24_0_1_20170116220224657 .jpg.chip.jpg\n",
      "- 39_1_20170116174525125.jpg.chip.jpg\n",
      "- 61_1_20170109142408075.jpg.chip.jpg\n",
      "- 61_1_20170109150557335.jpg.chip.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "invalid_file_paths = []\n",
    "\n",
    "# Filtrar imágenes con etiquetas válidas\n",
    "try:\n",
    "    all_files = glob(f\"{IMAGE_PATH}/*.jpg\")\n",
    "    if not all_files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No se encontraron archivos en el directorio {IMAGE_PATH}\"\n",
    "        )\n",
    "\n",
    "    for file_path in tqdm(all_files, desc=\"Filtrando imágenes\"):\n",
    "        filename = os.path.basename(file_path)\n",
    "        match = FILENAME_PATTERN.match(filename)\n",
    "\n",
    "        if match:\n",
    "            [gender] = match.groups()\n",
    "            data.append(\n",
    "                {\n",
    "                    \"file_path\": filename,\n",
    "                    \"gender\": int(gender),\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            invalid_file_paths.append(filename)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"\\n¡Filtrado completado con éxito!\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\nError de ruta: {e}\")\n",
    "    df = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"\\nError inesperado: {e}\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "if invalid_file_paths:\n",
    "    print(f\"\\nImágenes con etiqueta inválida: {len(invalid_file_paths)}\")\n",
    "    for file in invalid_file_paths:\n",
    "        print(f\"- {file}\")\n",
    "else:\n",
    "    print(\"\\nSe filtraron todas las imágenes correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcd73e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensión objetivo en píxeles\n",
    "TARGET_SIZE = (32, 32)\n",
    "\n",
    "\n",
    "def preprocess_image(filename: str, images_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocesa una imagen: redimensiona, convierte a escala de grises y normaliza.\n",
    "\n",
    "    Args:\n",
    "        filename: Nombre del archivo de la imagen.\n",
    "        images_path: Ruta del directorio que contiene las imágenes.\n",
    "\n",
    "    Returns:\n",
    "        Vector numpy con la imagen preprocesada.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(images_path, filename)\n",
    "\n",
    "    try:\n",
    "        img = cv2.imread(file_path)\n",
    "\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Error al cargar la imagen: {file_path}\")\n",
    "\n",
    "        # Redimensionar a tamaño objetivo\n",
    "        img = cv2.resize(img, TARGET_SIZE)\n",
    "        # Convertir a escala de grises\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Normalizar a rango [0, 1]\n",
    "        img = img / 255.0\n",
    "\n",
    "        # Aplanar la imagen en un vector\n",
    "        vector = img.flatten()\n",
    "\n",
    "        return vector\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error inesperado al procesar la imagen: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5306b86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocesando imágenes: 100%|██████████| 23704/23704 [00:11<00:00, 2049.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡Preprocesamiento completado!\n",
      "\n",
      "Se procesaron todas las imágenes correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_vectors = []\n",
    "valid_indices = []\n",
    "invalid_images = []\n",
    "\n",
    "# Preprocesar imágenes y almacenar vectores válidos\n",
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Preprocesando imágenes\"):\n",
    "    vector = preprocess_image(row[\"file_path\"], IMAGE_PATH)\n",
    "\n",
    "    if vector is not None:\n",
    "        image_vectors.append(vector)\n",
    "        valid_indices.append(index)\n",
    "    else:\n",
    "        invalid_images.append(row[\"file_path\"])\n",
    "\n",
    "print(f\"\\n¡Preprocesamiento completado!\")\n",
    "\n",
    "if invalid_images:\n",
    "    print(f\"\\nImágenes no procesadas: {len(invalid_images)}\")\n",
    "    for img in invalid_images:\n",
    "        print(f\"- {img}\")\n",
    "else:\n",
    "    print(\"\\nSe procesaron todas las imágenes correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea0c5931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Datos preparados!\n",
      "\n",
      "Dimensión de la matriz de datos X: (23704, 1024)\n",
      "Dimensión del vector de etiquetas y: (23704,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(image_vectors)\n",
    "\n",
    "df = df.loc[valid_indices].reset_index(drop=True)\n",
    "y = df[\"gender\"].values\n",
    "\n",
    "print(\"¡Datos preparados!\")\n",
    "print(f\"\\nDimensión de la matriz de datos X: {X.shape}\")\n",
    "print(f\"Dimensión del vector de etiquetas y: {y.shape}\")\n",
    "\n",
    "# Borrar variables temporales para liberar memoria\n",
    "del image_vectors, valid_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a918f36",
   "metadata": {},
   "source": [
    "### División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9663e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "VALIDATION_SIZE = 0.2\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "029534ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡División de datos completada!\n",
      "\n",
      "Dimensiones de los conjuntos:\n",
      "- Entrenamiento (60%): X_train: (14222, 1024), y_train: (14222,)\n",
      "- Validación (20%): X_val: (4741, 1024), y_val: (4741,)\n",
      "- Prueba (20%): X_test: (4741, 1024), y_test: (4741,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separar el conjunto de prueba del resto de los datos\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "# Separar el conjunto de validación del conjunto de entrenamiento\n",
    "VALIDATION_SIZE_ADJUSTED = VALIDATION_SIZE / (1 - TEST_SIZE)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=VALIDATION_SIZE_ADJUSTED,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y_temp,\n",
    ")\n",
    "\n",
    "print(\"¡División de datos completada!\")\n",
    "print(f\"\\nDimensiones de los conjuntos:\")\n",
    "print(\n",
    "    f\"- Entrenamiento ({round((1 - TEST_SIZE - VALIDATION_SIZE)*100)}%): X_train: {X_train.shape}, y_train: {y_train.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"- Validación ({round(VALIDATION_SIZE*100)}%): X_val: {X_val.shape}, y_val: {y_val.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"- Prueba ({round(TEST_SIZE*100)}%): X_test: {X_test.shape}, y_test: {y_test.shape}\"\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "del X_temp, y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42191e1",
   "metadata": {},
   "source": [
    "### Análisis mediante PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
